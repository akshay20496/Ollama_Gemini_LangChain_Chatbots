{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367139d8-5438-4993-93e2-2380a4e5448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variable\n",
    "api_key = os.getenv(\"GEMINI_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e96d209-535d-4a4c-898c-4c5478dfc3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTranslate the following to Hindi:\n",
      "How are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The most common and natural translation of \"How are you?\" to Hindi is:\n",
      "\n",
      "**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
      "(Aap kaise hain?)\n",
      "\n",
      "*   **‡§Ü‡§™ (Aap)** means \"you\" (formal/respectful).\n",
      "*   **‡§ï‡•à‡§∏‡•á (kaise)** means \"how\".\n",
      "*   **‡§π‡•à‡§Ç (hain)** means \"are\" (plural/respectful form of \"is\").\n",
      "\n",
      "**Other variations:**\n",
      "\n",
      "*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - Used for friends, family, or people younger than you (informal).\n",
      "*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - Very informal, used for close friends, or sometimes considered rude if not used appropriately.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set your Gemini API key\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "\n",
    "# Create Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=gemini_api_key)\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\"Translate the following to Hindi:\\n{text}\")\n",
    "\n",
    "# LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "\n",
    "# Run the chain\n",
    "output = chain.run(\"How are you?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e232ac5-a28b-4963-bc11-30c1de039d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTranslate the following to Hindi:\n",
      "How are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'text': 'The most common and natural translation of \"How are you?\" to Hindi is:\\n\\n**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\\n(Aap kaise hain?)\\n\\n*   **‡§Ü‡§™ (Aap)** means \"you\" (formal/respectful).\\n*   **‡§ï‡•à‡§∏‡•á (kaise)** means \"how\".\\n*   **‡§π‡•à‡§Ç (hain)** means \"are\" (plural/respectful form of \"‡§π‡•à - hai\").\\n\\n**Other common variations:**\\n\\n*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - Used for friends, family, or people your age/younger (less formal than \"‡§Ü‡§™\").\\n*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - Very informal, used for close friends or family, or children.\\n*   **‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Kaisa hai?) - Informal, often used among male friends (implies \"How are you, male?\").\\n*   **‡§ï‡•à‡§∏‡•Ä ‡§π‡•ã?** (Kaisi ho?) - Informal, often used among female friends (implies \"How are you, female?\").'}\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set your Gemini API key\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "\n",
    "# Create Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=gemini_api_key)\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\"Translate the following to Hindi:\\n{text}\")\n",
    "\n",
    "# LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, verbose=True)\n",
    "\n",
    "# Run the chain\n",
    "output = chain.invoke(\"How are you?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc89168-973f-4880-a6f2-615e4688a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural translation of \"How are you?\" to Hindi is:\n",
      "\n",
      "**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
      "(Aap kaise hain?)\n",
      "\n",
      "*   **‡§Ü‡§™ (Aap)** means \"you\" (formal/respectful).\n",
      "*   **‡§ï‡•à‡§∏‡•á (kaise)** means \"how\".\n",
      "*   **‡§π‡•à‡§Ç (hain)** means \"are\" (plural/respectful form of \"‡§π‡•à - hai\").\n",
      "\n",
      "**Other common variations:**\n",
      "\n",
      "*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - Used for friends, family, or people your age/younger (less formal than \"‡§Ü‡§™\").\n",
      "*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - Very informal, used for close friends or family, or children.\n",
      "*   **‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Kaisa hai?) - Informal, often used among male friends (implies \"How are you, male?\").\n",
      "*   **‡§ï‡•à‡§∏‡•Ä ‡§π‡•ã?** (Kaisi ho?) - Informal, often used among female friends (implies \"How are you, female?\").\n"
     ]
    }
   ],
   "source": [
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761aa45-7297-4947-830c-a97a528c9d10",
   "metadata": {},
   "source": [
    "**LangChain Expression Language(LCEL)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9705ad88-1248-4cd7-a58c-1626b7534ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural way to say \"How are you?\" in Hindi is:\n",
      "\n",
      "**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
      "(Aap kaise hain?)\n",
      "\n",
      "*   **‡§Ü‡§™ (Aap)** is the respectful form of \"you\".\n",
      "*   **‡§ï‡•à‡§∏‡•á (Kaise)** means \"how\".\n",
      "*   **‡§π‡•à‡§Ç (Hain)** is the plural/respectful form of \"are\".\n",
      "\n",
      "You might also hear:\n",
      "\n",
      "*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - This is for friends or people you are very familiar with (informal \"you\").\n",
      "*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - This is very informal and used only with very close friends or family, or in some cases, to show disrespect.\n"
     ]
    }
   ],
   "source": [
    "# Old way\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run(\"How are you?\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8268c41-6ac5-4875-8a1b-2217fb3b039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The most common and natural translation of \"How are you?\" to Hindi is:\\n\\n**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\\n(Aap kaise hain?)\\n\\n*   **‡§Ü‡§™** (Aap) - You (formal/polite)\\n*   **‡§ï‡•à‡§∏‡•á** (kaise) - how\\n*   **‡§π‡•à‡§Ç** (hain) - are (plural/formal \\'is\\')\\n\\nIf you want to use the informal \"you\" (to friends, family members of similar age, children), you would say:\\n\\n*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - You (informal) how are?\\n*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - You (very informal/singular) how is? (Less common in general conversation, often used with very close friends or to younger people/children).' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--8ed4bf6f-aeb9-4014-bda0-0036051aecf3-0'\n"
     ]
    }
   ],
   "source": [
    "# New way\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({\"text\": \"How are you?\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fde496e4-b457-40fd-a0cb-335efe11e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and natural translation of \"How are you?\" to Hindi is:\n",
      "\n",
      "**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
      "(Aap kaise hain?)\n",
      "\n",
      "*   **‡§Ü‡§™** (Aap) - You (formal/polite)\n",
      "*   **‡§ï‡•à‡§∏‡•á** (kaise) - how\n",
      "*   **‡§π‡•à‡§Ç** (hain) - are (plural/formal 'is')\n",
      "\n",
      "If you want to use the informal \"you\" (to friends, family members of similar age, children), you would say:\n",
      "\n",
      "*   **‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?** (Tum kaise ho?) - You (informal) how are?\n",
      "*   **‡§§‡•Ç ‡§ï‡•à‡§∏‡§æ ‡§π‡•à?** (Tu kaisa hai?) - You (very informal/singular) how is? (Less common in general conversation, often used with very close friends or to younger people/children).\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "211c44a6-f608-4ddd-a70b-dde8236ce060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common and polite way to translate \"How are you?\" to Hindi is:\n",
      "\n",
      "**‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
      "(Aap kaise hain?)\n",
      "\n",
      "*   **‡§Ü‡§™ (Aap)**: You (formal/polite)\n",
      "*   **‡§ï‡•à‡§∏‡•á (kaise)**: How\n",
      "*   **‡§π‡•à‡§Ç (hain)**: Are (formal/plural form of \"to be\")\n",
      "\n",
      "If you are speaking to someone you know well, like a friend or family member of similar age, you could also say:\n",
      "\n",
      "**‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?**\n",
      "(Tum kaise ho?)\n",
      "\n",
      "*   **‡§§‡•Å‡§Æ (Tum)**: You (informal)\n",
      "*   **‡§ï‡•à‡§∏‡•á (kaise)**: How\n",
      "*   **‡§π‡•ã (ho)**: Are (informal form of \"to be\")\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Set your API key\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", api_key=gemini_api_key)\n",
    "\n",
    "# Define prompt\n",
    "prompt = PromptTemplate.from_template(\"Translate the following to Hindi:\\n{text}\")\n",
    "\n",
    "# Build LCEL-style chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke({\"text\": \"How are you?\"})\n",
    "print(result.content)  # Use .content for Gemini output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23313bf-b977-495d-8fa4-42f66b347c8e",
   "metadata": {},
   "source": [
    "| Scenario                      | Recommended Chain               |\n",
    "| ----------------------------- | ------------------------------- |\n",
    "| Teaching beginners            | `LLMChain` or `LCEL`            |\n",
    "| Need memory (chat history)    | `ConversationChain`             |\n",
    "| Answering questions from docs | `RetrievalQA`                   |\n",
    "| Step-by-step transformations  | `SequentialChain`               |\n",
    "| Routing based on input type   | `RouterChain`                   |\n",
    "| Production modular pipelines  | **LCEL (`RunnableSequence`)** ‚úÖ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82ade0-7ffd-4524-ad4c-9cd0297ea772",
   "metadata": {},
   "source": [
    "## ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e49057-69bb-4a84-a6fc-dfa083b7a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Hi Akshay! It's nice to meet you. I'm a large language model, trained by Google. I'm excited to chat with you today. I can try my best to answer your questions and provide helpful information. Do you have anything you'd like to talk about or ask me? I'm particularly good at things like summarizing factual topics, creating stories, and translating languages, but I'm always learning new things! What are you up to today? \n",
      "\n",
      "Response 2: Your name is Akshay. \n",
      "\n",
      "Response 3: Cursor AI is an AI-powered code editor designed to enhance developer productivity. It's built on top of VS Code and incorporates features like:\n",
      "\n",
      "*   **AI-powered code generation:** It can generate code snippets, functions, or even entire files based on natural language prompts or existing code. Think of it as having an AI pair programmer that can write boilerplate code, suggest implementations, and fill in missing pieces.\n",
      "*   **Contextual code completion:** Cursor AI leverages its understanding of your project and code context to provide more accurate and relevant code suggestions as you type. This goes beyond simple keyword completion and considers the surrounding code, variables, and functions to offer intelligent recommendations.\n",
      "*   **Code understanding and explanation:** You can ask Cursor AI to explain a particular section of code, and it will provide a human-readable explanation of its functionality. This can be very helpful for understanding unfamiliar codebases or quickly grasping the purpose of a specific function.\n",
      "*   **Debugging assistance:** Cursor AI can help you debug your code by identifying potential errors, suggesting fixes, and providing explanations of error messages. It can also help you write unit tests to ensure the quality and reliability of your code.\n",
      "*   **Code refactoring:** Cursor AI can assist with refactoring your code to improve its readability, maintainability, and performance. It can suggest improvements, automate common refactoring tasks, and help you identify areas of your code that could be improved.\n",
      "*   **Integration with other tools:** Cursor AI integrates with other popular developer tools, such as Git, GitHub, and Docker, to provide a seamless development experience.\n",
      "\n",
      "Essentially, Cursor AI aims to streamline the coding process by automating repetitive tasks, providing intelligent assistance, and helping developers understand and navigate complex codebases more effectively. It competes with other AI coding assistants like GitHub Copilot and Tabnine. It's a rapidly evolving area, so new features and improvements are constantly being added. \n",
      "\n",
      "\n",
      "Memory Chat History:\n",
      " [HumanMessage(content=\"Hi, I'm Akshay.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Akshay! It's nice to meet you. I'm a large language model, trained by Google. I'm excited to chat with you today. I can try my best to answer your questions and provide helpful information. Do you have anything you'd like to talk about or ask me? I'm particularly good at things like summarizing factual topics, creating stories, and translating languages, but I'm always learning new things! What are you up to today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Akshay.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is cursor AI?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Cursor AI is an AI-powered code editor designed to enhance developer productivity. It's built on top of VS Code and incorporates features like:\\n\\n*   **AI-powered code generation:** It can generate code snippets, functions, or even entire files based on natural language prompts or existing code. Think of it as having an AI pair programmer that can write boilerplate code, suggest implementations, and fill in missing pieces.\\n*   **Contextual code completion:** Cursor AI leverages its understanding of your project and code context to provide more accurate and relevant code suggestions as you type. This goes beyond simple keyword completion and considers the surrounding code, variables, and functions to offer intelligent recommendations.\\n*   **Code understanding and explanation:** You can ask Cursor AI to explain a particular section of code, and it will provide a human-readable explanation of its functionality. This can be very helpful for understanding unfamiliar codebases or quickly grasping the purpose of a specific function.\\n*   **Debugging assistance:** Cursor AI can help you debug your code by identifying potential errors, suggesting fixes, and providing explanations of error messages. It can also help you write unit tests to ensure the quality and reliability of your code.\\n*   **Code refactoring:** Cursor AI can assist with refactoring your code to improve its readability, maintainability, and performance. It can suggest improvements, automate common refactoring tasks, and help you identify areas of your code that could be improved.\\n*   **Integration with other tools:** Cursor AI integrates with other popular developer tools, such as Git, GitHub, and Docker, to provide a seamless development experience.\\n\\nEssentially, Cursor AI aims to streamline the coding process by automating repetitive tasks, providing intelligent assistance, and helping developers understand and navigate complex codebases more effectively. It competes with other AI coding assistants like GitHub Copilot and Tabnine. It's a rapidly evolving area, so new features and improvements are constantly being added.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize Gemini model (You need your API key set in env variable GOOGLE_API_KEY)\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=gemini_api_key)\n",
    "\n",
    "# Setup memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Build conversation chain\n",
    "chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# Run conversation\n",
    "response1 = chain.run(\"Hi, I'm Akshay.\")\n",
    "response2 = chain.run(\"What is my name?\")\n",
    "response3 = chain.run(\"What is cursor AI?\")\n",
    "\n",
    "print(\"Response 1:\", response1, '\\n')\n",
    "print(\"Response 2:\", response2, '\\n')\n",
    "print(\"Response 3:\", response3, '\\n')\n",
    "\n",
    "# View memory contents\n",
    "print(\"\\nMemory Chat History:\\n\", memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "416a82fc-dd5e-4082-9302-ed8aafc637dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Hi, I'm Akshay.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Akshay! It's nice to meet you. I'm a large language model, trained by Google. I'm excited to chat with you today. I can try my best to answer your questions and provide helpful information. Do you have anything you'd like to talk about or ask me? I'm particularly good at things like summarizing factual topics, creating stories, and translating languages, but I'm always learning new things! What are you up to today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Akshay.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is cursor AI?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Cursor AI is an AI-powered code editor designed to enhance developer productivity. It's built on top of VS Code and incorporates features like:\\n\\n*   **AI-powered code generation:** It can generate code snippets, functions, or even entire files based on natural language prompts or existing code. Think of it as having an AI pair programmer that can write boilerplate code, suggest implementations, and fill in missing pieces.\\n*   **Contextual code completion:** Cursor AI leverages its understanding of your project and code context to provide more accurate and relevant code suggestions as you type. This goes beyond simple keyword completion and considers the surrounding code, variables, and functions to offer intelligent recommendations.\\n*   **Code understanding and explanation:** You can ask Cursor AI to explain a particular section of code, and it will provide a human-readable explanation of its functionality. This can be very helpful for understanding unfamiliar codebases or quickly grasping the purpose of a specific function.\\n*   **Debugging assistance:** Cursor AI can help you debug your code by identifying potential errors, suggesting fixes, and providing explanations of error messages. It can also help you write unit tests to ensure the quality and reliability of your code.\\n*   **Code refactoring:** Cursor AI can assist with refactoring your code to improve its readability, maintainability, and performance. It can suggest improvements, automate common refactoring tasks, and help you identify areas of your code that could be improved.\\n*   **Integration with other tools:** Cursor AI integrates with other popular developer tools, such as Git, GitHub, and Docker, to provide a seamless development experience.\\n\\nEssentially, Cursor AI aims to streamline the coding process by automating repetitive tasks, providing intelligent assistance, and helping developers understand and navigate complex codebases more effectively. It competes with other AI coding assistants like GitHub Copilot and Tabnine. It's a rapidly evolving area, so new features and improvements are constantly being added.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acce27ab-42a8-425b-89ce-4d1730e2f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0e27962-2cac-42f6-830e-d3b37025169c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi, I'm Akshay.\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "325ccc5e-e60e-4b06-bac2-a39448dbc5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "867e97cd-0441-4781-aefc-c9b280f69ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Akshay! It's nice to meet you. I'm a large language model, trained by Google. I'm excited to chat with you today. I can try my best to answer your questions and provide helpful information. Do you have anything you'd like to talk about or ask me? I'm particularly good at things like summarizing factual topics, creating stories, and translating languages, but I'm always learning new things! What are you up to today?\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2df624fd-9ff5-471b-91eb-9889cc07ae30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages[1].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9dc607fc-e7f6-441e-8973-06b28f98073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 4: You're very welcome, Akshay! I'm glad I could provide you with helpful information about Cursor AI. Is there anything else I can help you with today? Perhaps you'd like to know how Cursor AI compares to other AI coding assistants, or maybe you have a specific task you'd like to see how it could help with? Just let me know!\n"
     ]
    }
   ],
   "source": [
    "response4 = chain.run(\"Thank you for this information.\")\n",
    "print(\"Response 4:\", response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7ee04a0-07af-4dd2-ad58-c5d80aa3328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human : Hi, I'm Akshay.\n",
      "\n",
      "ai : Hi Akshay! It's nice to meet you. I'm a large language model, trained by Google. I'm excited to chat with you today. I can try my best to answer your questions and provide helpful information. Do you have anything you'd like to talk about or ask me? I'm particularly good at things like summarizing factual topics, creating stories, and translating languages, but I'm always learning new things! What are you up to today?\n",
      "\n",
      "human : What is my name?\n",
      "\n",
      "ai : Your name is Akshay.\n",
      "\n",
      "human : What is cursor AI?\n",
      "\n",
      "ai : Cursor AI is an AI-powered code editor designed to enhance developer productivity. It's built on top of VS Code and incorporates features like:\n",
      "\n",
      "*   **AI-powered code generation:** It can generate code snippets, functions, or even entire files based on natural language prompts or existing code. Think of it as having an AI pair programmer that can write boilerplate code, suggest implementations, and fill in missing pieces.\n",
      "*   **Contextual code completion:** Cursor AI leverages its understanding of your project and code context to provide more accurate and relevant code suggestions as you type. This goes beyond simple keyword completion and considers the surrounding code, variables, and functions to offer intelligent recommendations.\n",
      "*   **Code understanding and explanation:** You can ask Cursor AI to explain a particular section of code, and it will provide a human-readable explanation of its functionality. This can be very helpful for understanding unfamiliar codebases or quickly grasping the purpose of a specific function.\n",
      "*   **Debugging assistance:** Cursor AI can help you debug your code by identifying potential errors, suggesting fixes, and providing explanations of error messages. It can also help you write unit tests to ensure the quality and reliability of your code.\n",
      "*   **Code refactoring:** Cursor AI can assist with refactoring your code to improve its readability, maintainability, and performance. It can suggest improvements, automate common refactoring tasks, and help you identify areas of your code that could be improved.\n",
      "*   **Integration with other tools:** Cursor AI integrates with other popular developer tools, such as Git, GitHub, and Docker, to provide a seamless development experience.\n",
      "\n",
      "Essentially, Cursor AI aims to streamline the coding process by automating repetitive tasks, providing intelligent assistance, and helping developers understand and navigate complex codebases more effectively. It competes with other AI coding assistants like GitHub Copilot and Tabnine. It's a rapidly evolving area, so new features and improvements are constantly being added.\n",
      "\n",
      "human : Thank you for this information.\n",
      "\n",
      "ai : You're very welcome, Akshay! I'm glad I could provide you with helpful information about Cursor AI. Is there anything else I can help you with today? Perhaps you'd like to know how Cursor AI compares to other AI coding assistants, or maybe you have a specific task you'd like to see how it could help with? Just let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type} : {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0af2d-dff7-4b26-8c82-b4b7485f3e30",
   "metadata": {},
   "source": [
    "**Retrieval QA used in RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c76cc9-2634-4449-80f4-5ac59b0605af",
   "metadata": {},
   "source": [
    "## Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27f21428-9099-4c93-9e52-8340024e65c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Final Output ---\n",
      "Title: Here are some engaging blog titles about the benefits of learning LangChain in 2025, catering to different audiences and angles:\n",
      "\n",
      "**Focusing on Career Advancement:**\n",
      "\n",
      "*   **LangChain in 2025: Your Fast Track to AI Career Success**\n",
      "*   **Level Up Your AI Skills: Why LangChain is a Must-Learn in 2025**\n",
      "*   **Future-Proof Your Career: The Untapped Potential of LangChain in 2025**\n",
      "*   **Land Your Dream AI Job: Mastering LangChain for 2025 and Beyond**\n",
      "\n",
      "**Highlighting Practical Applications:**\n",
      "\n",
      "*   **Beyond the Hype: Real-World Benefits of Learning LangChain in 2025**\n",
      "*   **Build Smarter AI: Why LangChain Will Be Your Secret Weapon in 2025**\n",
      "*   **From Zero to Hero: Mastering LangChain for Powerful AI Applications in 2025**\n",
      "*   **Unlock the Power of LLMs: A Practical Guide to LangChain in 2025**\n",
      "\n",
      "**Emphasizing Future Trends:**\n",
      "\n",
      "*   **The Future of AI is Here: Why LangChain Will Dominate in 2025**\n",
      "*   **Riding the AI Wave: Why Learning LangChain Now Sets You Up for 2025**\n",
      "*   **LangChain in 2025: The Key to Unlocking Advanced AI Capabilities**\n",
      "*   **Predicting the AI Landscape: Why LangChain is a Critical Skill for 2025**\n",
      "\n",
      "**Intriguing and Click-Worthy:**\n",
      "\n",
      "*   **Don't Get Left Behind: Why You Need to Learn LangChain Before 2025**\n",
      "*   **The AI Skill You Can't Afford to Ignore: LangChain in 2025**\n",
      "*   **LangChain: The AI Game Changer You Need to Know About in 2025**\n",
      "*   **Is LangChain the Future of AI? Why You Should Care in 2025**\n",
      "\n",
      "**More Specific & Targeted:**\n",
      "\n",
      "*   **LangChain for Developers: Building the Next Generation of AI Apps in 2025**\n",
      "*   **LangChain for Businesses: Automate, Innovate, and Outperform in 2025**\n",
      "*   **LangChain for Researchers: Pushing the Boundaries of AI in 2025**\n",
      "\n",
      "When choosing, consider:\n",
      "\n",
      "*   **Your target audience:** Who are you trying to reach?\n",
      "*   **The main benefits you want to emphasize:** What's the most compelling reason to learn LangChain?\n",
      "*   **Search Engine Optimization (SEO):** Include relevant keywords like \"LangChain,\" \"AI,\" \"2025,\" and \"benefits.\"\n",
      "\n",
      "Good luck! \n",
      "\n",
      "\n",
      "Summary: **Is LangChain the Key to Your AI Future? Get Ready for 2025!**\n",
      "\n",
      "Thinking about leveling up your AI skills? This post explores compelling reasons why learning LangChain is a smart move, and provides a range of catchy blog titles to get you thinking. Whether you're a developer, business leader, or researcher, we've got titles focused on career advancement, practical applications, future trends, and more. Discover how LangChain can help you build smarter AI, future-proof your career, and unlock the power of LLMs in 2025 and beyond! \n",
      "\n",
      "\n",
      "Tweet: Is LangChain the key to your AI future? üîë This blog post explores why learning LangChain is a smart move for devs, leaders & researchers looking to build smarter AI in 2025! Plus, we've got catchy blog titles to inspire you. Check it out! [Link to blog post] #LangChain #AI #LLM #ArtificialIntelligence #FutureofAI\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key = gemini_api_key, temperature=0.7, top_k=50)\n",
    "\n",
    "# Step 1: Topic ‚Üí Title\n",
    "title_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate an engaging blog title about {topic}.\"\n",
    ")\n",
    "title_chain = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")\n",
    "\n",
    "# Step 2: Title ‚Üí Summary\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"title\"],\n",
    "    template=\"Write a short blog summary for the title: {title}\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt, output_key=\"summary\")\n",
    "\n",
    "# Step 3: Summary ‚Üí Tweet\n",
    "tweet_prompt = PromptTemplate(\n",
    "    input_variables=[\"summary\"],\n",
    "    template=\"Write a tweet promoting this blog post: {summary}\"\n",
    ")\n",
    "tweet_chain = LLMChain(llm=llm, prompt=tweet_prompt, output_key=\"tweet\")\n",
    "\n",
    "# Build Sequential Chain\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[title_chain, summary_chain, tweet_chain],\n",
    "    input_variables=[\"topic\"],\n",
    "    output_variables=[\"title\", \"summary\", \"tweet\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Use invoke instead of run\n",
    "result = overall_chain.invoke({\"topic\": \"Benefits of learning LangChain in 2025\"})\n",
    "\n",
    "print(\"\\n--- Final Output ---\")\n",
    "print(\"Title:\", result[\"title\"],'\\n\\n')\n",
    "print(\"Summary:\", result[\"summary\"],'\\n\\n')\n",
    "print(\"Tweet:\", result[\"tweet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b6c8d-ef10-4cb8-8df0-9f4d23c727af",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "328a5069-f6dd-48d8-a768-ec7d517133df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Beginner-Friendly LCEL Output ---\n",
      "Title: Of course! Here are several engaging blog titles about the benefits of learning LangChain in 2025, categorized by style.\n",
      "\n",
      "### Catchy & Intriguing\n",
      "*   **LangChain in 2025: The AI Skill That Will Separate the Pros from the Amateurs**\n",
      "*   **Beyond the Hype: Why LangChain is Your Secret Weapon for 2025**\n",
      "*   **The AI Gold Rush of 2025: LangChain is Your Pickaxe**\n",
      "*   **Don't Get Left Behind: The #1 Reason to Master LangChain Before 2025**\n",
      "*   **2025 is Coming. Is LangChain in Your Tech Stack?**\n",
      "\n",
      "### Benefit-Focused & Direct\n",
      "*   **Future-Proof Your Career: 5 Game-Changing Benefits of Learning LangChain in 2025**\n",
      "*   **Unlock Next-Level AI: How LangChain Will Supercharge Your Development in 2025**\n",
      "*   **From Prompting to Production: Why LangChain is the Essential Bridge for Developers in 2025**\n",
      "*   **The ROI of Learning: How Mastering LangChain in 2025 Pays Dividends**\n",
      "*   **Build Smarter, Not Harder: The Power of LangChain for AI Applications in 2025**\n",
      "\n",
      "### Question-Based (Sparks Curiosity)\n",
      "*   **Is LangChain Still Relevant in 2025? (Spoiler: More Than Ever)**\n",
      "*   **Want to Build Real-World AI Apps in 2025? Here's Why You Need LangChain.**\n",
      "*   **What Will the Most In-Demand AI Skill of 2025 Be? Hint: It Connects to LLMs.**\n",
      "*   **Are You Ready for the Next Wave of AI? Why Your Answer Depends on LangChain.**\n",
      "\n",
      "### For a More Technical Audience\n",
      "*   **The 2025 Developer's Edge: Mastering Agents and RAG with LangChain**\n",
      "*   **LangChain in 2025: Architecting Complex LLM Workflows for Production**\n",
      "*   **Why LangChain Will Be the Core of Your AI/ML Ops Stack in 2025**\n",
      "\n",
      "**Pro-Tip:** For the best engagement, pair one of these titles with a compelling subtitle. For example:\n",
      "\n",
      "*   **Title:** The AI Gold Rush of 2025: LangChain is Your Pickaxe\n",
      "*   **Subtitle:** *Discover the essential benefits of this powerful framework and why it's the key to building valuable AI products next year.* \n",
      "\n",
      "\n",
      "Summary: Of course. Since the titles you provided have different tones (some catchy, some technical), here are two short blog summary options that you can adapt.\n",
      "\n",
      "### Option 1: For a General / Catchy Title\n",
      "\n",
      "**(e.g., \"The AI Gold Rush of 2025: LangChain is Your Pickaxe\")**\n",
      "\n",
      "> As we head into 2025, the AI landscape is evolving faster than ever. It's no longer enough to just interact with large language models; the real value lies in building sophisticated applications on top of them. This post dives into why LangChain is the essential framework you need to master. We'll explore how it acts as the bridge between AI theory and real-world production, enabling you to build powerful, data-aware agents and complex workflows. Discover the key benefits that will future-proof your career and give you the competitive edge in the new year.\n",
      "\n",
      "### Option 2: For a More Technical / Direct Title\n",
      "\n",
      "**(e.g., \"The 2025 Developer's Edge: Mastering Agents and RAG with LangChain\")**\n",
      "\n",
      "> In 2025, developers looking to excel in AI will need to move beyond basic API calls. This article explores the critical role of LangChain as the go-to framework for architecting complex LLM applications. We'll break down the practical benefits of mastering LangChain, focusing on two key areas: implementing advanced Retrieval-Augmented Generation (RAG) to connect models to custom data, and building autonomous agents capable of complex reasoning and tool use. Learn why this framework is becoming an indispensable part of the modern AI/ML Ops stack and how it will supercharge your development capabilities. \n",
      "\n",
      "\n",
      "Tweet: Of course! Here are a few options for a tweet, tailored for different tones.\n",
      "\n",
      "### Option 1 (Catchy & General)\n",
      "\n",
      "The 2025 AI Gold Rush is on. LangChain is your pickaxe. ‚õèÔ∏è\n",
      "\n",
      "Our latest post breaks down why this framework is essential for building powerful AI agents and future-proofing your career. Get the competitive edge.\n",
      "\n",
      "Read more: [LINK]\n",
      "\n",
      "#AI #LangChain #LLM #GenAI\n",
      "\n",
      "---\n",
      "\n",
      "### Option 2 (Technical & Direct)\n",
      "\n",
      "Ready to level up your AI dev skills for 2025?\n",
      "\n",
      "Move beyond basic API calls and master LangChain. We break down how to build advanced RAG pipelines and autonomous agents, supercharging your capabilities.\n",
      "\n",
      "Dive deep into the go-to LLM framework: [LINK]\n",
      "\n",
      "#LangChain #RAG #AIagents #LLMs #Python #MLOps\n",
      "\n",
      "---\n",
      "\n",
      "### Option 3 (Concise & Punchy)\n",
      "\n",
      "Are your AI skills ready for 2025? It's time to build, not just prompt.\n",
      "\n",
      "Learn why LangChain is the essential framework for creating complex, data-aware AI applications with advanced RAG and agents.\n",
      "\n",
      "Your developer's edge starts here: [LINK]\n",
      "\n",
      "#AI #Developer #MachineLearning #LangChain \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "\n",
    "# Step 1: Setup LLM\n",
    "gemini_api_key = \"Use-your-api-key\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0.7, api_key=gemini_api_key)\n",
    "\n",
    "# Step 2: Prompts\n",
    "title_prompt = PromptTemplate.from_template(\"Generate an engaging blog title about {topic}.\")\n",
    "summary_prompt = PromptTemplate.from_template(\"Write a short blog summary for the title: {title}\")\n",
    "tweet_prompt = PromptTemplate.from_template(\"Write a tweet promoting this blog post: {summary}\")\n",
    "\n",
    "# Step 3: Chains\n",
    "title_chain = title_prompt | llm\n",
    "summary_chain = summary_prompt | llm\n",
    "tweet_chain = tweet_prompt | llm\n",
    "\n",
    "# Step 4: Sequential Execution in Steps\n",
    "\n",
    "# First: get the title from the topic\n",
    "title = title_chain.invoke({\"topic\": \"Benefits of learning LangChain in 2025\"})\n",
    "\n",
    "# Second: get the summary from the title\n",
    "summary = summary_chain.invoke({\"title\": title})\n",
    "\n",
    "# Third: get the tweet from the summary\n",
    "tweet = tweet_chain.invoke({\"summary\": summary})\n",
    "\n",
    "# Step 5: Final Output\n",
    "print(\"\\n--- Beginner-Friendly LCEL Output ---\")\n",
    "print(\"Title:\", title.content,'\\n\\n')\n",
    "print(\"Summary:\", summary.content,'\\n\\n')\n",
    "print(\"Tweet:\", tweet.content,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "25991f2c-c265-41de-94af-b57ac33f74bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are several engaging blog titles about the benefits of learning LangChain in 2025, categorized by style.\n",
      "\n",
      "### Catchy & Intriguing\n",
      "*   **LangChain in 2025: The AI Skill That Will Separate the Pros from the Amateurs**\n",
      "*   **Beyond the Hype: Why LangChain is Your Secret Weapon for 2025**\n",
      "*   **The AI Gold Rush of 2025: LangChain is Your Pickaxe**\n",
      "*   **Don't Get Left Behind: The #1 Reason to Master LangChain Before 2025**\n",
      "*   **2025 is Coming. Is LangChain in Your Tech Stack?**\n",
      "\n",
      "### Benefit-Focused & Direct\n",
      "*   **Future-Proof Your Career: 5 Game-Changing Benefits of Learning LangChain in 2025**\n",
      "*   **Unlock Next-Level AI: How LangChain Will Supercharge Your Development in 2025**\n",
      "*   **From Prompting to Production: Why LangChain is the Essential Bridge for Developers in 2025**\n",
      "*   **The ROI of Learning: How Mastering LangChain in 2025 Pays Dividends**\n",
      "*   **Build Smarter, Not Harder: The Power of LangChain for AI Applications in 2025**\n",
      "\n",
      "### Question-Based (Sparks Curiosity)\n",
      "*   **Is LangChain Still Relevant in 2025? (Spoiler: More Than Ever)**\n",
      "*   **Want to Build Real-World AI Apps in 2025? Here's Why You Need LangChain.**\n",
      "*   **What Will the Most In-Demand AI Skill of 2025 Be? Hint: It Connects to LLMs.**\n",
      "*   **Are You Ready for the Next Wave of AI? Why Your Answer Depends on LangChain.**\n",
      "\n",
      "### For a More Technical Audience\n",
      "*   **The 2025 Developer's Edge: Mastering Agents and RAG with LangChain**\n",
      "*   **LangChain in 2025: Architecting Complex LLM Workflows for Production**\n",
      "*   **Why LangChain Will Be the Core of Your AI/ML Ops Stack in 2025**\n",
      "\n",
      "**Pro-Tip:** For the best engagement, pair one of these titles with a compelling subtitle. For example:\n",
      "\n",
      "*   **Title:** The AI Gold Rush of 2025: LangChain is Your Pickaxe\n",
      "*   **Subtitle:** *Discover the essential benefits of this powerful framework and why it's the key to building valuable AI products next year.*\n"
     ]
    }
   ],
   "source": [
    "print(title.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f6c2cf3-ddef-495d-83a3-8fb17d9a62b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Since the titles you provided have different tones (some catchy, some technical), here are two short blog summary options that you can adapt.\n",
      "\n",
      "### Option 1: For a General / Catchy Title\n",
      "\n",
      "**(e.g., \"The AI Gold Rush of 2025: LangChain is Your Pickaxe\")**\n",
      "\n",
      "> As we head into 2025, the AI landscape is evolving faster than ever. It's no longer enough to just interact with large language models; the real value lies in building sophisticated applications on top of them. This post dives into why LangChain is the essential framework you need to master. We'll explore how it acts as the bridge between AI theory and real-world production, enabling you to build powerful, data-aware agents and complex workflows. Discover the key benefits that will future-proof your career and give you the competitive edge in the new year.\n",
      "\n",
      "### Option 2: For a More Technical / Direct Title\n",
      "\n",
      "**(e.g., \"The 2025 Developer's Edge: Mastering Agents and RAG with LangChain\")**\n",
      "\n",
      "> In 2025, developers looking to excel in AI will need to move beyond basic API calls. This article explores the critical role of LangChain as the go-to framework for architecting complex LLM applications. We'll break down the practical benefits of mastering LangChain, focusing on two key areas: implementing advanced Retrieval-Augmented Generation (RAG) to connect models to custom data, and building autonomous agents capable of complex reasoning and tool use. Learn why this framework is becoming an indispensable part of the modern AI/ML Ops stack and how it will supercharge your development capabilities.\n"
     ]
    }
   ],
   "source": [
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "298229f3-157f-46d1-b962-4e9f9f47cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here are a few options for a tweet, tailored for different tones.\n",
      "\n",
      "### Option 1 (Catchy & General)\n",
      "\n",
      "The 2025 AI Gold Rush is on. LangChain is your pickaxe. ‚õèÔ∏è\n",
      "\n",
      "Our latest post breaks down why this framework is essential for building powerful AI agents and future-proofing your career. Get the competitive edge.\n",
      "\n",
      "Read more: [LINK]\n",
      "\n",
      "#AI #LangChain #LLM #GenAI\n",
      "\n",
      "---\n",
      "\n",
      "### Option 2 (Technical & Direct)\n",
      "\n",
      "Ready to level up your AI dev skills for 2025?\n",
      "\n",
      "Move beyond basic API calls and master LangChain. We break down how to build advanced RAG pipelines and autonomous agents, supercharging your capabilities.\n",
      "\n",
      "Dive deep into the go-to LLM framework: [LINK]\n",
      "\n",
      "#LangChain #RAG #AIagents #LLMs #Python #MLOps\n",
      "\n",
      "---\n",
      "\n",
      "### Option 3 (Concise & Punchy)\n",
      "\n",
      "Are your AI skills ready for 2025? It's time to build, not just prompt.\n",
      "\n",
      "Learn why LangChain is the essential framework for creating complex, data-aware AI applications with advanced RAG and agents.\n",
      "\n",
      "Your developer's edge starts here: [LINK]\n",
      "\n",
      "#AI #Developer #MachineLearning #LangChain\n"
     ]
    }
   ],
   "source": [
    "print(tweet.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a820a87-1cee-4ca3-9c49-5efddee14867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

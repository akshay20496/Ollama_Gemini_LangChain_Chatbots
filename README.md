# ğŸ§  Multi-Model LLM Chatbots with LangChain, Gemini & Ollama

This project demonstrates end-to-end chatbot applications using LangChain with Gemini and Ollama models. It covers the implementation of memory, chaining, and RAG pipelines using Streamlit interfaces and Python notebooks.

---

## ğŸ“‚ Project Structure

| File/Folder                      | Description |
|----------------------------------|-------------|
| `Chains_end_to_end.ipynb`        | Demonstrates LangChain chains using the Gemini model |
| `Langchain_memory.ipynb`         | Explores memory concepts (e.g., buffer memory) with Gemini |
| `Gemini_Chat_BOt_different_UI.py`| Streamlit chatbot using Gemini with custom UI and memory |
| `chatbot_ollama.py`              | Streamlit chatbot using Ollama with session memory and styling |
| `requirements.txt`               | Required Python packages |

---

## ğŸš€ Features

- âœ… Chatbots using **Gemini** and **Ollama**
- âœ… **Streamlit-based** front-end with custom styling
- âœ… Chat **history and memory** using LangChain
- âœ… Use of **LangChain chains** and RAG principles
- âœ… Modular, readable, and beginner-friendly notebooks

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name

